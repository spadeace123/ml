{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5ESAaOM18q4",
        "outputId": "15607c84-20a4-4a4a-b3fe-f0f0ae00fa89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.18.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
            "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from jiwer) (3.12.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install groq\n",
        "!pip install jiwer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gPlMUlOz18n-"
      },
      "outputs": [],
      "source": [
        "import os # Ensure os module is imported for file path operations\n",
        "from main import Transcribe, WER, Evaluate\n",
        "\n",
        "# Specifying the API KEY\n",
        "# Insert API Key from Groq Cloud here\n",
        "os.environ[\"GROQ_API_KEY\"] = \"XXXX\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "xqk6lBKH18k2",
        "outputId": "92a48ca1-b459-4449-ea6d-f347e3339c4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription saved to Custom-Home-Builder_transcript.txt\n",
            "WER calculation saved to Custom-Home-Builder_transcript_wer_output.txt\n",
            "Transformed text saved to Custom-Home-Builder_transcript_transform.txt\n",
            "Evaluation saved to Custom-Home-Builder_transcript_transform_evaluation.txt\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Custom-Home-Builder_transcript_transform_evaluation.txt'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Path to the audio file to be transcribed\n",
        "audio_file_path = \"/content/Custom-Home-Builder.mp3\"\n",
        "\n",
        "# Specify the transcription and evaluation models\n",
        "transcribe_model = \"whisper-large-v3\"  # Model used for transcribing speech to text\n",
        "evaluate_model = \"deepseek-r1-distill-llama-70b\"  # Model used for evaluation of the transformed text\n",
        "\n",
        "# Perform transcription on the given audio file using the specified model\n",
        "Transcribe(audio_file_path, transcribe_model)\n",
        "\n",
        "# Extract the file name (without extension) from the given audio file path\n",
        "file_name = os.path.splitext(os.path.basename(audio_file_path))[0]\n",
        "\n",
        "# Define the file paths for ground truth and transcribed text\n",
        "ground_truth_file = f\"{file_name}.txt\"  # Reference file containing the correct transcript\n",
        "transcript_file = f\"{file_name}_transcript.txt\"  # File where the generated transcript is stored\n",
        "\n",
        "# Compute Word Error Rate (WER) by comparing the transcribed output with the ground truth\n",
        "WER(ground_truth_file, transcript_file)\n",
        "\n",
        "# Extract the file name (without extension) from the transcript file\n",
        "file_name = os.path.splitext(os.path.basename(transcript_file))[0]\n",
        "\n",
        "# Define the file path for the transformed text\n",
        "transform_file = f\"{file_name}_transform.txt\"\n",
        "\n",
        "# Perform evaluation on the transformed text using the specified model\n",
        "Evaluate(transform_file, evaluate_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "xwapDIgZ18hz",
        "outputId": "a9d959e2-99c3-4db5-e62d-ab2543422699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription saved to Inbound-sales-audio-sample_transcript.txt\n",
            "WER calculation saved to Inbound-sales-audio-sample_transcript_wer_output.txt\n",
            "Transformed text saved to Inbound-sales-audio-sample_transcript_transform.txt\n",
            "Evaluation saved to Inbound-sales-audio-sample_transcript_transform_evaluation.txt\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Inbound-sales-audio-sample_transcript_transform_evaluation.txt'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Path to the audio file to be transcribed\n",
        "audio_file_path = \"/content/Inbound-sales-audio-sample.mp3\"\n",
        "\n",
        "# Specify the transcription and evaluation models\n",
        "transcribe_model = \"whisper-large-v3\"  # Model used for transcribing speech to text\n",
        "evaluate_model = \"deepseek-r1-distill-llama-70b\"  # Model used for evaluation of the transformed text\n",
        "\n",
        "# Perform transcription on the given audio file using the specified model\n",
        "Transcribe(audio_file_path, transcribe_model)\n",
        "\n",
        "# Extract the file name (without extension) from the given audio file path\n",
        "file_name = os.path.splitext(os.path.basename(audio_file_path))[0]\n",
        "\n",
        "# Define the file paths for ground truth and transcribed text\n",
        "ground_truth_file = f\"{file_name}.txt\"  # Reference file containing the correct transcript\n",
        "transcript_file = f\"{file_name}_transcript.txt\"  # File where the generated transcript is stored\n",
        "\n",
        "# Compute Word Error Rate (WER) by comparing the transcribed output with the ground truth\n",
        "WER(ground_truth_file, transcript_file)\n",
        "\n",
        "# Extract the file name (without extension) from the transcript file\n",
        "file_name = os.path.splitext(os.path.basename(transcript_file))[0]\n",
        "\n",
        "# Define the file path for the transformed text\n",
        "transform_file = f\"{file_name}_transform.txt\"\n",
        "\n",
        "# Perform evaluation on the transformed text using the specified model\n",
        "Evaluate(transform_file, evaluate_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "nrySD0_R9MQb",
        "outputId": "7e2595b7-13c7-42ab-cc7b-4912e536450a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription saved to Local-Plumber_transcript.txt\n",
            "WER calculation saved to Local-Plumber_transcript_wer_output.txt\n",
            "Transformed text saved to Local-Plumber_transcript_transform.txt\n",
            "Evaluation saved to Local-Plumber_transcript_transform_evaluation.txt\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Local-Plumber_transcript_transform_evaluation.txt'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Path to the audio file to be transcribed\n",
        "audio_file_path = \"/content/Local-Plumber.mp3\"\n",
        "\n",
        "# Specify the transcription and evaluation models\n",
        "transcribe_model = \"whisper-large-v3\"  # Model used for transcribing speech to text\n",
        "evaluate_model = \"deepseek-r1-distill-llama-70b\"  # Model used for evaluation of the transformed text\n",
        "\n",
        "# Perform transcription on the given audio file using the specified model\n",
        "Transcribe(audio_file_path, transcribe_model)\n",
        "\n",
        "# Extract the file name (without extension) from the given audio file path\n",
        "file_name = os.path.splitext(os.path.basename(audio_file_path))[0]\n",
        "\n",
        "# Define the file paths for ground truth and transcribed text\n",
        "ground_truth_file = f\"{file_name}.txt\"  # Reference file containing the correct transcript\n",
        "transcript_file = f\"{file_name}_transcript.txt\"  # File where the generated transcript is stored\n",
        "\n",
        "# Compute Word Error Rate (WER) by comparing the transcribed output with the ground truth\n",
        "WER(ground_truth_file, transcript_file)\n",
        "\n",
        "# Extract the file name (without extension) from the transcript file\n",
        "file_name = os.path.splitext(os.path.basename(transcript_file))[0]\n",
        "\n",
        "# Define the file path for the transformed text\n",
        "transform_file = f\"{file_name}_transform.txt\"\n",
        "\n",
        "# Perform evaluation on the transformed text using the specified model\n",
        "Evaluate(transform_file, evaluate_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "lwBCBuSZ9Kur",
        "outputId": "4a4fcd47-3f15-423d-e7bb-d8a048257b1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription saved to Property-Management-Office_transcript.txt\n",
            "WER calculation saved to Property-Management-Office_transcript_wer_output.txt\n",
            "Transformed text saved to Property-Management-Office_transcript_transform.txt\n",
            "Evaluation saved to Property-Management-Office_transcript_transform_evaluation.txt\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Property-Management-Office_transcript_transform_evaluation.txt'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Path to the audio file to be transcribed\n",
        "audio_file_path = \"/content/Property-Management-Office.mp3\"\n",
        "\n",
        "# Specify the transcription and evaluation models\n",
        "transcribe_model = \"whisper-large-v3\"  # Model used for transcribing speech to text\n",
        "evaluate_model = \"deepseek-r1-distill-llama-70b\"  # Model used for evaluation of the transformed text\n",
        "\n",
        "# Perform transcription on the given audio file using the specified model\n",
        "Transcribe(audio_file_path, transcribe_model)\n",
        "\n",
        "# Extract the file name (without extension) from the given audio file path\n",
        "file_name = os.path.splitext(os.path.basename(audio_file_path))[0]\n",
        "\n",
        "# Define the file paths for ground truth and transcribed text\n",
        "ground_truth_file = f\"{file_name}.txt\"  # Reference file containing the correct transcript\n",
        "transcript_file = f\"{file_name}_transcript.txt\"  # File where the generated transcript is stored\n",
        "\n",
        "# Compute Word Error Rate (WER) by comparing the transcribed output with the ground truth\n",
        "WER(ground_truth_file, transcript_file)\n",
        "\n",
        "# Extract the file name (without extension) from the transcript file\n",
        "file_name = os.path.splitext(os.path.basename(transcript_file))[0]\n",
        "\n",
        "# Define the file path for the transformed text\n",
        "transform_file = f\"{file_name}_transform.txt\"\n",
        "\n",
        "# Perform evaluation on the transformed text using the specified model\n",
        "Evaluate(transform_file, evaluate_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "qjXPiSOH9KR4",
        "outputId": "257559b3-1c97-4360-d740-81fdb846e39e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription saved to Real-State-Lead-Gen-1_transcript.txt\n",
            "WER calculation saved to Real-State-Lead-Gen-1_transcript_wer_output.txt\n",
            "Transformed text saved to Real-State-Lead-Gen-1_transcript_transform.txt\n",
            "Evaluation saved to Real-State-Lead-Gen-1_transcript_transform_evaluation.txt\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Real-State-Lead-Gen-1_transcript_transform_evaluation.txt'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Path to the audio file to be transcribed\n",
        "audio_file_path = \"/content/Real-State-Lead-Gen-1.mp3\"\n",
        "\n",
        "# Specify the transcription and evaluation models\n",
        "transcribe_model = \"whisper-large-v3\"  # Model used for transcribing speech to text\n",
        "evaluate_model = \"deepseek-r1-distill-llama-70b\"  # Model used for evaluation of the transformed text\n",
        "\n",
        "# Perform transcription on the given audio file using the specified model\n",
        "Transcribe(audio_file_path, transcribe_model)\n",
        "\n",
        "# Extract the file name (without extension) from the given audio file path\n",
        "file_name = os.path.splitext(os.path.basename(audio_file_path))[0]\n",
        "\n",
        "# Define the file paths for ground truth and transcribed text\n",
        "ground_truth_file = f\"{file_name}.txt\"  # Reference file containing the correct transcript\n",
        "transcript_file = f\"{file_name}_transcript.txt\"  # File where the generated transcript is stored\n",
        "\n",
        "# Compute Word Error Rate (WER) by comparing the transcribed output with the ground truth\n",
        "WER(ground_truth_file, transcript_file)\n",
        "\n",
        "# Extract the file name (without extension) from the transcript file\n",
        "file_name = os.path.splitext(os.path.basename(transcript_file))[0]\n",
        "\n",
        "# Define the file path for the transformed text\n",
        "transform_file = f\"{file_name}_transform.txt\"\n",
        "\n",
        "# Perform evaluation on the transformed text using the specified model\n",
        "Evaluate(transform_file, evaluate_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "sbAgGJPk9Rg-",
        "outputId": "4b598a48-a7bf-408e-8033-56a1dd8ad6c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription saved to Travel-Reservation_transcript.txt\n",
            "WER calculation saved to Travel-Reservation_transcript_wer_output.txt\n",
            "Transformed text saved to Travel-Reservation_transcript_transform.txt\n",
            "Evaluation saved to Travel-Reservation_transcript_transform_evaluation.txt\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Travel-Reservation_transcript_transform_evaluation.txt'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Path to the audio file to be transcribed\n",
        "audio_file_path = \"/content/Travel-Reservation.mp3\"\n",
        "\n",
        "# Specify the transcription and evaluation models\n",
        "transcribe_model = \"whisper-large-v3\"  # Model used for transcribing speech to text\n",
        "evaluate_model = \"deepseek-r1-distill-llama-70b\"  # Model used for evaluation of the transformed text\n",
        "\n",
        "# Perform transcription on the given audio file using the specified model\n",
        "Transcribe(audio_file_path, transcribe_model)\n",
        "\n",
        "# Extract the file name (without extension) from the given audio file path\n",
        "file_name = os.path.splitext(os.path.basename(audio_file_path))[0]\n",
        "\n",
        "# Define the file paths for ground truth and transcribed text\n",
        "ground_truth_file = f\"{file_name}.txt\"  # Reference file containing the correct transcript\n",
        "transcript_file = f\"{file_name}_transcript.txt\"  # File where the generated transcript is stored\n",
        "\n",
        "# Compute Word Error Rate (WER) by comparing the transcribed output with the ground truth\n",
        "WER(ground_truth_file, transcript_file)\n",
        "\n",
        "# Extract the file name (without extension) from the transcript file\n",
        "file_name = os.path.splitext(os.path.basename(transcript_file))[0]\n",
        "\n",
        "# Define the file path for the transformed text\n",
        "transform_file = f\"{file_name}_transform.txt\"\n",
        "\n",
        "# Perform evaluation on the transformed text using the specified model\n",
        "Evaluate(transform_file, evaluate_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-D-S7G5a_GT7"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-n1qMx0bALdd",
        "outputId": "943ed34e-f262-4e68-ba88-94ec696096eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/Custom-Home-Builder.mp3 (deflated 22%)\n",
            "  adding: content/Custom-Home-Builder_transcript_transform_evaluation.txt (deflated 64%)\n",
            "  adding: content/Custom-Home-Builder_transcript_transform.txt (deflated 83%)\n",
            "  adding: content/Custom-Home-Builder_transcript.txt (deflated 47%)\n",
            "  adding: content/Custom-Home-Builder_transcript_wer_output.txt (deflated 82%)\n",
            "  adding: content/Custom-Home-Builder.txt (deflated 46%)\n",
            "  adding: content/Inbound-sales-audio-sample.mp3 (deflated 2%)\n",
            "  adding: content/Inbound-sales-audio-sample_transcript_transform_evaluation.txt (deflated 68%)\n",
            "  adding: content/Inbound-sales-audio-sample_transcript_transform.txt (deflated 86%)\n",
            "  adding: content/Inbound-sales-audio-sample_transcript.txt (deflated 55%)\n",
            "  adding: content/Inbound-sales-audio-sample_transcript_wer_output.txt (deflated 86%)\n",
            "  adding: content/Inbound-sales-audio-sample.txt (deflated 55%)\n",
            "  adding: content/Local-Plumber.mp3 (deflated 23%)\n",
            "  adding: content/Local-Plumber_transcript_transform_evaluation.txt (deflated 58%)\n",
            "  adding: content/Local-Plumber_transcript_transform.txt (deflated 83%)\n",
            "  adding: content/Local-Plumber_transcript.txt (deflated 46%)\n",
            "  adding: content/Local-Plumber_transcript_wer_output.txt (deflated 82%)\n",
            "  adding: content/Local-Plumber.txt (deflated 46%)\n",
            "  adding: content/main.py (deflated 69%)\n",
            "  adding: content/Property-Management-Office.mp3 (deflated 26%)\n",
            "  adding: content/Property-Management-Office_transcript_transform_evaluation.txt (deflated 59%)\n",
            "  adding: content/Property-Management-Office_transcript_transform.txt (deflated 84%)\n",
            "  adding: content/Property-Management-Office_transcript.txt (deflated 49%)\n",
            "  adding: content/Property-Management-Office_transcript_wer_output.txt (deflated 83%)\n",
            "  adding: content/Property-Management-Office.txt (deflated 49%)\n",
            "  adding: content/__pycache__/ (stored 0%)\n",
            "  adding: content/__pycache__/main.cpython-311.pyc (deflated 58%)\n",
            "  adding: content/Real-State-Lead-Gen-1.mp3 (deflated 2%)\n",
            "  adding: content/Real-State-Lead-Gen-1_transcript_transform_evaluation.txt (deflated 59%)\n",
            "  adding: content/Real-State-Lead-Gen-1_transcript_transform.txt (deflated 85%)\n",
            "  adding: content/Real-State-Lead-Gen-1_transcript.txt (deflated 53%)\n",
            "  adding: content/Real-State-Lead-Gen-1_transcript_wer_output.txt (deflated 85%)\n",
            "  adding: content/Real-State-Lead-Gen-1.txt (deflated 53%)\n",
            "  adding: content/sample_data/ (stored 0%)\n",
            "  adding: content/sample_data/README.md (deflated 39%)\n",
            "  adding: content/sample_data/anscombe.json (deflated 83%)\n",
            "  adding: content/sample_data/mnist_train_small.csv (deflated 88%)\n",
            "  adding: content/sample_data/california_housing_test.csv (deflated 76%)\n",
            "  adding: content/sample_data/california_housing_train.csv (deflated 79%)\n",
            "  adding: content/sample_data/mnist_test.csv (deflated 88%)\n",
            "  adding: content/Travel-Reservation.mp3 (deflated 32%)\n",
            "  adding: content/Travel-Reservation_transcript_transform_evaluation.txt (deflated 62%)\n",
            "  adding: content/Travel-Reservation_transcript_transform.txt (deflated 86%)\n",
            "  adding: content/Travel-Reservation_transcript.txt (deflated 56%)\n",
            "  adding: content/Travel-Reservation_transcript_wer_output.txt (deflated 86%)\n",
            "  adding: content/Travel-Reservation.txt (deflated 56%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/ITI108_2958340N_outputs.zip /content/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "PSmbTQl8ALY3",
        "outputId": "ab3e10bc-5438-48a4-fa9e-d4b7ea31bc39"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_bafde085-d2db-4f39-a992-b988e2ebd9a8\", \"ITI108_2958340N_outputs.zip\", 16859032)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "files.download(\"/content/ITI108_2958340N_outputs.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BU2T3PCjALDV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
